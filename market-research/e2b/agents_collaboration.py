#!/usr/bin/env python3
"""
E2B Agents åä½œç¤ºä¾‹
æ¼”ç¤ºå¤šä¸ª agents å¦‚ä½•åœ¨æ²™ç®±ä¸­äº¤äº’å’Œå…±äº«æ•°æ®

åœºæ™¯ï¼š
1. æ•°æ®åˆ†æå¸ˆ Agent - å¤„ç†å’Œåˆ†ææ•°æ®
2. å¯è§†åŒ– Agent - ç”Ÿæˆå›¾è¡¨
3. æŠ¥å‘Šç”Ÿæˆ Agent - åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š
"""

from pathlib import Path
from dotenv import load_dotenv
from e2b import Sandbox
import json
import time

# åŠ è½½ API Key
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

print("=" * 60)
print("E2B Agents åä½œæ¼”ç¤º")
print("=" * 60)

# åˆ›å»ºå…±äº«çš„æ²™ç®±ç¯å¢ƒ
print("\nğŸš€ åˆ›å»ºå…±äº«æ²™ç®±ç¯å¢ƒ...")
sandbox = Sandbox.create()
print(f"âœ… æ²™ç®± ID: {sandbox.sandbox_id}")

try:
    # ============================================
    # åœºæ™¯ 1: é€šè¿‡æ–‡ä»¶ç³»ç»Ÿå…±äº«æ•°æ®
    # ============================================
    print("\n" + "=" * 60)
    print("åœºæ™¯ 1: Agent é€šè¿‡æ–‡ä»¶ç³»ç»Ÿå…±äº«æ•°æ®")
    print("=" * 60)

    # Agent 1: æ•°æ®é‡‡é›†
    print("\nğŸ“Š Agent 1: æ•°æ®é‡‡é›†")
    raw_data = {
        "sales": [100, 150, 200, 180, 220],
        "months": ["Jan", "Feb", "Mar", "Apr", "May"],
        "product": "Widget A"
    }

    # å°†æ•°æ®å†™å…¥å…±äº«ä½ç½®
    sandbox.files.write(
        "/tmp/shared/raw_data.json",
        json.dumps(raw_data, indent=2)
    )
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: /tmp/shared/raw_data.json")
    print(f"   æ•°æ®: {raw_data}")

    # Agent 2: æ•°æ®åˆ†æ
    print("\nğŸ” Agent 2: æ•°æ®åˆ†æ")
    analysis_script = """
import json

# è¯»å– Agent 1 çš„æ•°æ®
with open('/tmp/shared/raw_data.json', 'r') as f:
    data = json.load(f)

# æ‰§è¡Œåˆ†æ
sales = data['sales']
analysis = {
    'total_sales': sum(sales),
    'average_sales': sum(sales) / len(sales),
    'max_sales': max(sales),
    'min_sales': min(sales),
    'product': data['product']
}

# ä¿å­˜åˆ†æç»“æœä¾›å…¶ä»– agents ä½¿ç”¨
with open('/tmp/shared/analysis_result.json', 'w') as f:
    json.dump(analysis, f, indent=2)

print('åˆ†æå®Œæˆï¼')
print(json.dumps(analysis, indent=2))
"""

    sandbox.files.write("/tmp/shared/analyze.py", analysis_script)
    result = sandbox.commands.run("python3 /tmp/shared/analyze.py")
    print(f"âœ… åˆ†æç»“æœ:\n{result.stdout}")

    # Agent 3: æŠ¥å‘Šç”Ÿæˆ
    print("\nğŸ“ Agent 3: æŠ¥å‘Šç”Ÿæˆ")
    report_script = """
import json

# è¯»å–åŸå§‹æ•°æ®å’Œåˆ†æç»“æœ
with open('/tmp/shared/raw_data.json', 'r') as f:
    raw_data = json.load(f)

with open('/tmp/shared/analysis_result.json', 'r') as f:
    analysis = json.load(f)

# ç”ŸæˆæŠ¥å‘Š
report = f'''
é”€å”®æŠ¥å‘Š - {analysis['product']}
{'=' * 40}

æ€»é”€å”®é¢: ${analysis['total_sales']}
å¹³å‡é”€å”®é¢: ${analysis['average_sales']:.2f}
æœ€é«˜é”€å”®é¢: ${analysis['max_sales']}
æœ€ä½é”€å”®é¢: ${analysis['min_sales']}

æœˆåº¦æ˜ç»†:
'''

for month, sale in zip(raw_data['months'], raw_data['sales']):
    report += f"  {month}: ${sale}\\n"

# ä¿å­˜æŠ¥å‘Š
with open('/tmp/shared/final_report.txt', 'w') as f:
    f.write(report)

print(report)
"""

    sandbox.files.write("/tmp/shared/generate_report.py", report_script)
    result = sandbox.commands.run("python3 /tmp/shared/generate_report.py")
    print(f"âœ… æœ€ç»ˆæŠ¥å‘Š:\n{result.stdout}")

    # ============================================
    # åœºæ™¯ 2: æµæ°´çº¿å¤„ç†ï¼ˆPipelineï¼‰
    # ============================================
    print("\n" + "=" * 60)
    print("åœºæ™¯ 2: Agent æµæ°´çº¿å¤„ç†")
    print("=" * 60)

    # Pipeline Stage 1: æ•°æ®æ¸…æ´—
    print("\nğŸ§¹ Stage 1: æ•°æ®æ¸…æ´— Agent")
    cleaning_script = """
import json

# æ¨¡æ‹Ÿå«æœ‰å™ªå£°çš„æ•°æ®
raw_data = [100, 150, -1, 200, None, 180, 220, 999999]

# æ¸…æ´—æ•°æ®
cleaned_data = [x for x in raw_data if x is not None and 0 < x < 1000]

result = {
    'stage': 'cleaning',
    'input_count': len(raw_data),
    'output_count': len(cleaned_data),
    'data': cleaned_data
}

with open('/tmp/pipeline/stage1_output.json', 'w') as f:
    json.dump(result, f)

print(f'æ¸…æ´—å®Œæˆ: {len(raw_data)} -> {len(cleaned_data)} æ¡è®°å½•')
"""

    sandbox.files.write("/tmp/pipeline/stage1_clean.py", cleaning_script)
    result = sandbox.commands.run("python3 /tmp/pipeline/stage1_clean.py")
    print(f"âœ… {result.stdout}")

    # Pipeline Stage 2: æ•°æ®è½¬æ¢
    print("\nğŸ”„ Stage 2: æ•°æ®è½¬æ¢ Agent")
    transform_script = """
import json

# è¯»å–ä¸Šä¸€é˜¶æ®µçš„è¾“å‡º
with open('/tmp/pipeline/stage1_output.json', 'r') as f:
    stage1 = json.load(f)

# è½¬æ¢æ•°æ®ï¼ˆä¾‹å¦‚ï¼šæ ‡å‡†åŒ–ï¼‰
data = stage1['data']
mean = sum(data) / len(data)
std = (sum((x - mean) ** 2 for x in data) / len(data)) ** 0.5

normalized_data = [(x - mean) / std for x in data]

result = {
    'stage': 'transform',
    'mean': mean,
    'std': std,
    'normalized_data': normalized_data
}

with open('/tmp/pipeline/stage2_output.json', 'w') as f:
    json.dump(result, f)

print(f'è½¬æ¢å®Œæˆ: mean={mean:.2f}, std={std:.2f}')
"""

    sandbox.files.write("/tmp/pipeline/stage2_transform.py", transform_script)
    result = sandbox.commands.run("python3 /tmp/pipeline/stage2_transform.py")
    print(f"âœ… {result.stdout}")

    # Pipeline Stage 3: ç»“æœèšåˆ
    print("\nğŸ“Š Stage 3: ç»“æœèšåˆ Agent")
    aggregate_script = """
import json

# è¯»å–æ‰€æœ‰é˜¶æ®µçš„è¾“å‡º
with open('/tmp/pipeline/stage1_output.json', 'r') as f:
    stage1 = json.load(f)

with open('/tmp/pipeline/stage2_output.json', 'r') as f:
    stage2 = json.load(f)

# èšåˆç»“æœ
final_result = {
    'pipeline_summary': {
        'stage1_cleaning': f"{stage1['input_count']} -> {stage1['output_count']} records",
        'stage2_transform': f"mean={stage2['mean']:.2f}, std={stage2['std']:.2f}",
    },
    'final_data': stage2['normalized_data']
}

with open('/tmp/pipeline/final_result.json', 'w') as f:
    json.dump(final_result, f, indent=2)

print('Pipeline å®Œæˆï¼')
print(json.dumps(final_result, indent=2))
"""

    sandbox.files.write("/tmp/pipeline/stage3_aggregate.py", aggregate_script)
    result = sandbox.commands.run("python3 /tmp/pipeline/stage3_aggregate.py")
    print(f"âœ… {result.stdout}")

    # ============================================
    # åœºæ™¯ 3: å¹¶è¡Œ Agents å¤„ç†
    # ============================================
    print("\n" + "=" * 60)
    print("åœºæ™¯ 3: å¹¶è¡Œ Agents åä½œ")
    print("=" * 60)

    # åˆ›å»ºå…±äº«è¾“å…¥æ•°æ®
    shared_input = {
        "text": "E2B provides secure sandboxed environments for AI agents",
        "numbers": [1, 2, 3, 4, 5]
    }
    sandbox.files.write("/tmp/parallel/input.json", json.dumps(shared_input))

    # Agent A: æ–‡æœ¬å¤„ç†
    print("\nğŸ“ Agent A: æ–‡æœ¬åˆ†æ")
    text_agent = """
import json

with open('/tmp/parallel/input.json', 'r') as f:
    data = json.load(f)

text = data['text']
result = {
    'agent': 'text_processor',
    'word_count': len(text.split()),
    'char_count': len(text),
    'uppercase': text.upper()
}

with open('/tmp/parallel/agent_a_result.json', 'w') as f:
    json.dump(result, f, indent=2)

print(f"æ–‡æœ¬å¤„ç†å®Œæˆ: {result['word_count']} words")
"""

    sandbox.files.write("/tmp/parallel/agent_a.py", text_agent)
    result = sandbox.commands.run("python3 /tmp/parallel/agent_a.py")
    print(f"âœ… {result.stdout}")

    # Agent B: æ•°å€¼å¤„ç†
    print("\nğŸ”¢ Agent B: æ•°å€¼è®¡ç®—")
    number_agent = """
import json

with open('/tmp/parallel/input.json', 'r') as f:
    data = json.load(f)

numbers = data['numbers']
result = {
    'agent': 'number_processor',
    'sum': sum(numbers),
    'average': sum(numbers) / len(numbers),
    'squared': [x**2 for x in numbers]
}

with open('/tmp/parallel/agent_b_result.json', 'w') as f:
    json.dump(result, f, indent=2)

print(f"æ•°å€¼å¤„ç†å®Œæˆ: sum={result['sum']}")
"""

    sandbox.files.write("/tmp/parallel/agent_b.py", number_agent)
    result = sandbox.commands.run("python3 /tmp/parallel/agent_b.py")
    print(f"âœ… {result.stdout}")

    # Coordinator Agent: æ•´åˆç»“æœ
    print("\nğŸ¯ Coordinator Agent: æ•´åˆæ‰€æœ‰ç»“æœ")
    coordinator = """
import json

# è¯»å–æ‰€æœ‰ agent çš„ç»“æœ
with open('/tmp/parallel/agent_a_result.json', 'r') as f:
    agent_a = json.load(f)

with open('/tmp/parallel/agent_b_result.json', 'r') as f:
    agent_b = json.load(f)

# æ•´åˆç»“æœ
combined = {
    'agents_completed': ['text_processor', 'number_processor'],
    'results': {
        'text_analysis': agent_a,
        'number_analysis': agent_b
    },
    'summary': f"å¤„ç†äº† {agent_a['word_count']} ä¸ªå•è¯å’Œ {agent_b['sum']} çš„æ•°å­—æ€»å’Œ"
}

print('æ‰€æœ‰ Agents åä½œå®Œæˆï¼')
print(json.dumps(combined, indent=2))
"""

    sandbox.files.write("/tmp/parallel/coordinator.py", coordinator)
    result = sandbox.commands.run("python3 /tmp/parallel/coordinator.py")
    print(f"âœ… {result.stdout}")

    # ============================================
    # åœºæ™¯ 4: çŠ¶æ€å…±äº«ä¸åŒæ­¥
    # ============================================
    print("\n" + "=" * 60)
    print("åœºæ™¯ 4: Agent çŠ¶æ€å…±äº«")
    print("=" * 60)

    # ä½¿ç”¨é”æ–‡ä»¶å’ŒçŠ¶æ€æ–‡ä»¶è¿›è¡Œåè°ƒ
    print("\nğŸ”„ åˆå§‹åŒ–å…±äº«çŠ¶æ€")
    initial_state = {
        "task_queue": ["task1", "task2", "task3", "task4"],
        "completed_tasks": [],
        "agents_status": {}
    }
    sandbox.files.write("/tmp/state/shared_state.json", json.dumps(initial_state, indent=2))

    # æ¨¡æ‹Ÿå¤šä¸ª agent å¤„ç†ä»»åŠ¡
    for i in range(1, 4):
        agent_id = f"Agent_{i}"
        print(f"\nğŸ¤– {agent_id} å¤„ç†ä»»åŠ¡")

        # Agent å·¥ä½œå™¨è„šæœ¬
        worker_script = f"""
import json

agent_id = '{agent_id}'

# è¯»å–å…±äº«çŠ¶æ€
with open('/tmp/state/shared_state.json', 'r') as f:
    state = json.load(f)

# ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡
if state['task_queue']:
    task = state['task_queue'].pop(0)

    # æ‰§è¡Œä»»åŠ¡ï¼ˆæ¨¡æ‹Ÿï¼‰
    result = agent_id + " completed " + task
    state['completed_tasks'].append(result)
    state['agents_status'][agent_id] = 'completed'

    # æ›´æ–°çŠ¶æ€
    with open('/tmp/state/shared_state.json', 'w') as f:
        json.dump(state, f, indent=2)

    print(agent_id + ': ' + result)
else:
    print(agent_id + ': No tasks available')
"""

        script = worker_script
        sandbox.files.write(f"/tmp/state/worker_{i}.py", script)
        result = sandbox.commands.run(f"python3 /tmp/state/worker_{i}.py")
        print(f"   {result.stdout.strip()}")

    # æŸ¥çœ‹æœ€ç»ˆçŠ¶æ€
    print("\nğŸ“Š æŸ¥çœ‹æœ€ç»ˆå…±äº«çŠ¶æ€")
    final_state = sandbox.files.read("/tmp/state/shared_state.json")
    print(f"âœ… æœ€ç»ˆçŠ¶æ€:\n{final_state}")

    # ============================================
    # æŸ¥çœ‹æ‰€æœ‰å…±äº«æ–‡ä»¶
    # ============================================
    print("\n" + "=" * 60)
    print("ğŸ“ å…±äº«æ–‡ä»¶ç³»ç»Ÿæ¦‚è§ˆ")
    print("=" * 60)

    for directory in ["/tmp/shared", "/tmp/pipeline", "/tmp/parallel", "/tmp/state"]:
        result = sandbox.commands.run(f"find {directory} -type f 2>/dev/null || echo 'Directory not found'")
        if result.stdout.strip() and "not found" not in result.stdout:
            print(f"\n{directory}:")
            for line in result.stdout.strip().split('\n'):
                print(f"  - {line}")

finally:
    # æ¸…ç†èµ„æº
    print("\n" + "=" * 60)
    print("ğŸ§¹ æ¸…ç†æ²™ç®±èµ„æº...")
    sandbox.kill()
    print("âœ… å®Œæˆï¼")
    print("=" * 60)

print("\nğŸ’¡ æ€»ç»“:")
print("   1. æ–‡ä»¶ç³»ç»Ÿå…±äº« - Agents é€šè¿‡ JSON æ–‡ä»¶äº¤æ¢æ•°æ®")
print("   2. æµæ°´çº¿å¤„ç† - Agent é“¾å¼å¤„ç†ï¼Œè¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªçš„è¾“å…¥")
print("   3. å¹¶è¡Œåä½œ - å¤šä¸ª Agents åŒæ—¶å¤„ç†ï¼ŒCoordinator æ•´åˆç»“æœ")
print("   4. çŠ¶æ€åŒæ­¥ - å…±äº«çŠ¶æ€æ–‡ä»¶åè°ƒä»»åŠ¡åˆ†é…")
print("\nğŸ”— è¿™äº›æ¨¡å¼å¯ä»¥ç»„åˆä½¿ç”¨ï¼Œæ„å»ºå¤æ‚çš„ Multi-Agent ç³»ç»Ÿ")
